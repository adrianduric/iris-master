From the curve of the metric scores, we see that both accuracy and mAP increase from start to finish. For both metrics, the increase is faster in the first few epochs, then grows more slowly in the latter ones. This makes sense as the model is the farthest away from some local optimum before being finetuned, and quickly reaches closer to one after some training. It is also important to notice that both metrics only increase by a few points; this is likely due to the pretrained ResNet18 model already being a good classifier prior to finetuning.

Correspondingly, we see similar curves for training and validation loss. Notice that validation loss seems to be significantly lower in magnitude than training loss, but still shows the same tendency of decreasing loss in its curve. This probably happens simply because the plot shows total calculated loss per epoch for the training and validation sets. Because the training set is significantly larger than the validation set, more loss is added to training loss than to validation loss. Thus, the magnitudes of the two curves are incomparable; the main takeaway is that the curves are similar.

From the PCA plots, we can see that the best, trained model has learned to separate the classes better than the untrained one; there are greater distances between datapoints of different classes for the trained model. We can also see which classes are easier and harder to classify; forests are the most different from the others and thus clustered on its own. Buildings and streets have much overlap, as is also the case for glaciers, mountains and seas, as suggested by the images from 1f).