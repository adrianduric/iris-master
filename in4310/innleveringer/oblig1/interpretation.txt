From the curve of the metric scores, we see that both accuracy and mAP increase from start to finish. For both metrics, the increase is faster the first few epochs, then grows more slowly in the latter ones. This makes sense as the model is the farthest away from some local optimum before being finetuned, and quickly reaches closer to one after some training. It is also important to notice that both metrics only increase by a few points; this is likely due to the pretrained ResNet18 model already being a good classifier prior to finetuning.

Correspondingly, we see similar curves for training and validation loss. Notice that validation loss seems to be significantly lower in magnitude than training loss, but still shows the same tendency of decreasing loss in its curve. This probably happens simply because the plot shows total calculated loss per epoch for the training and validation sets. Because the training set is significantly larger than the validation set, more loss is added to training loss than to validation loss. Thus, the magnitude of the two curves are incomparable; the main takeaway is that the curves are similar.